#   数据挖掘

[TOC]



## Jupyter Notebook

Jupyter项目是一个非盈利的开源项目，源于2014年的ipython项目，并逐渐发展为支持跨所有编程语言的交互式数据科学计算工具

- 是ipython的加强网页版，是一个开源的web程序
- 名字源有Julia，Python和R
- 是一款程序员和科学工作者的编辑、文档、笔记，展示软件
- .ipynb文件格式是用于计算型叙述的JSON文档格式的正式规范

为什么使用Jupyter？

- 画图方便的优势
- 数据展示方便的优势

### 快速上手Jupyter Notebook

界面启动 创建文件

在cmd窗口输入

```shell
jupyter notebook
```

新建notebook的文档格式是.ipynb

![image-20210905100022783](.\pic\image-20210905100022783.png)

![image-20210905095722397](.\pic\image-20210905095722397.png)

### cell操作

什么是cell？

cell：一对In Out会话被视为一个代码单元，称为cell

**Jupyter支持两种模式：**

- 编辑模式（Enter）

    命令模式下 `回车Enter` 或者 `鼠标点击` cell进入编辑模式

    可以操作cell内文本代码，剪切/复制/粘贴移动等操作

- 命令模式（Esc）

    按`Esc`退出编辑，进入命令模式

    可以`操作cell单元`本身进行剪切/复制/粘贴/移动等操作

**常用的快捷键：**

`Shift+Enter`	执行本单元代码，并跳转到下一单元

`Ctrl+Enter`	执行本单元代码，留在本单元

命令模式下：`A`	`B`	`双击D`

**markdown**

`# 一级标题`

`- 缩进`



## Matplotlib画图

什么是Matplotlib？

- 专门用于开发2D图表（包括3D图表）
- 使用起来及其简单
- 以渐进，交互式方式实现数据可视化

为什么学习Matplotlib ---画图

数据可视化，可视化是整个数据挖掘的关键辅助工具，可以清晰的理解数据，从而调整我们的分析方法

### 实现一个简单的Matplotlib画图

```python
import matplotlib.pyplot as plt
%matplotlib inline

plt.figure() # 创建一块画布
plt.plot([1, 0, 9], [4, 5, 6])
plt.show()
```

![image-20210905110614554](.\pic\image-20210905110614554.png)

### Matplotlib三层结构	

#### **容器层**

**画板层**(Canvas) ---**画布层**(Figure)plt.figure() ---**绘图区/坐标系**(axes)plt.subplots()

#### 辅助显示层

辅助显示层为Axes内除了根据数据绘制出来的图像以外的内容，该层的设置可以使图像显示更加直观更加容易被用户理解，但又不会对图像产生实际的影响

#### 图像层

图像层指的是通过plot，scatter，bar，histogram，pie等函数根据数据绘制出的图像

### 折线图plot与基础绘图功能

#### matplotlib.pyplot模块

matplotlib.pyplot包含了一系列类似于matplotlib的画图函数，它的函数作用于当前图形的当前坐标系

```python
import matplotlib.pyplot as plt
```

#### 折线图绘制与显示

```python
import matplotlib.pyplot as plt

# 创建画布
plt.figure()
# 绘制折线图
plt.plot([1, 2, 3, 4, 5, 6, 7], [17, 17, 18, 14, 11, 11, 13])
# 显示图像
plt.show()
```

![image-20210905113654039](.\pic\image-20210905113654039.png)

#### 设置画布属性与图片保存

```
plt.figure(figsize=(), dpi=)
	figsize:指定图的长宽
	dpi:图像的清洗度
	返回fig对象
plt.savefig(path)
```

```python
import matplotlib.pyplot as plt

# 创建画布
plt.figure(figsize=(20, 8), dpi=120)
# 绘制折线图
plt.plot([1, 2, 3, 4, 5, 6, 7], [17, 17, 18, 14, 11, 11, 13])

# 保存图像( 如果该行代码写到plt.show()后保存的图片是空白 )
plt.savefig("test.png")

# 显示图像
plt.show() # 会释放figure资源
```

![test](.\pic\test.png)

#### 完善原始折线图(辅助显示层)

```python
import matplotlib.pyplot as plt
import random

# 1 准备数据 x y
x = range(60)
y_shanghai = [random.uniform(15, 18) for i in x]

plt.figure(figsize=(20, 8), dpi=80)
plt.plot(x, y_shanghai)
plt.show()
```

![image-20210905115612134](.\pic\image-20210905115612134.png)

##### 中文问题解决

https://blog.csdn.net/gdhenry92/article/details/102930238

但是我不管用，所有找来以下解决方法

在代码中添加以下代码

```python
plt.rcParams['font.sans-serif']=['SimHei']  #用来正常显示中文标签
plt.rcParams['axes.unicode_minus']=False #用来正常显示负号
```

##### 修改x轴y轴刻度

```python
import matplotlib.pyplot as plt
import random

plt.rcParams['font.sans-serif']=['SimHei']  #用来正常显示中文标签
plt.rcParams['axes.unicode_minus']=False #用来正常显示负号
             
# 1 准备数据 x y
x = range(60)
y_shanghai = [random.uniform(15, 18) for i in x]

plt.figure(figsize=(20, 8), dpi=80)
plt.plot(x, y_shanghai)


# 修改x y刻度
x_label = ["11点{}分".format(i) for i in x] # 准备x的刻度说明a

plt.xticks(x[::5], x_label[::5])
plt.yticks(range(0, 40, 5))

plt.show()
```

![image-20210905160255509](.\pic\image-20210905160255509.png)

##### 添加网格

```python
plt.grid(True, linestyle='--', alpha=0.5) # 默认是true, 网格风格， 透明度
```

![image-20210905161514297](.\pic\image-20210905161514297.png)

##### 添加描述信息

```python
plt.xlabel("时间")
plt.ylabel("温度")
plt.title("中午11点0分到12点之间的温度变化图示")
```

```python
import matplotlib.pyplot as plt
import random

plt.rcParams['font.sans-serif']=['SimHei']  #用来正常显示中文标签
plt.rcParams['axes.unicode_minus']=False #用来正常显示负号
             
# 1 准备数据 x y
x = range(60)
y_shanghai = [random.uniform(15, 18) for i in x]

plt.figure(figsize=(20, 8), dpi=80)
plt.plot(x, y_shanghai)


# 修改x y刻度
x_label = ["11点{}分".format(i) for i in x] # 准备x的刻度说明a

plt.xticks(x[::5], x_label[::5])
plt.yticks(range(0, 40, 5))

plt.grid(True, linestyle='--', alpha=0.5) # 默认是true, 网格风格， 透明度

plt.xlabel("时间")
plt.ylabel("温度")
plt.title("中午11点0分到12点之间的温度变化图示")


plt.show()
```

![image-20210905161819192](.\pic\image-20210905161819192.png)

#### 完善原始折线图(图像层)

##### 多个plot

```python
import matplotlib.pyplot as plt
import random

plt.rcParams['font.sans-serif']=['SimHei']  #用来正常显示中文标签
plt.rcParams['axes.unicode_minus']=False #用来正常显示负号
             
# 1 准备数据 x y
x = range(60)
y_shanghai = [random.uniform(15, 18) for i in x]

plt.figure(figsize=(20, 8), dpi=80)
plt.plot(x, y_shanghai, color="r", label="上海")

# 准备另一个城市的数据
y_beijin = [random.uniform(1, 3) for i in x]
plt.plot(x, y_beijin, color="b", linestyle="-.", label="北京")

# 修改x y刻度
x_label = ["11点{}分".format(i) for i in x] # 准备x的刻度说明a

plt.xticks(x[::5], x_label[::5])
plt.yticks(range(0, 40, 5))


# 添加辅助显示层的样式
plt.grid(True, linestyle='--', alpha=0.5) # 默认是true, 网格风格， 透明度

plt.xlabel("时间")
plt.ylabel("温度")
plt.title("上海，北京中午11点0分到12点之间的温度变化图示")
# 显示图例
plt.legend(loc=0) # 修改显示的位置

plt.show()
```

![image-20210905163015887](.\pic\image-20210905163015887.png)

##### 多个坐标系显示-plt.subplots(面向对象的画图方法)

```python
figure, axes = plt.subplots(nrows=1, ncols=2, **fig_kw)
axes[0].方法名
axes[1].方法名
```

```python
import matplotlib.pyplot as plt
import random

plt.rcParams['font.sans-serif']=['SimHei']  #用来正常显示中文标签
plt.rcParams['axes.unicode_minus']=False #用来正常显示负号

x = range(60)
y_shanghai = [random.uniform(15, 18) for i in x]
y_beijing = [random.uniform(1, 4) for i in x]

# 创建画布
figure, axes = plt.subplots(nrows = 1, ncols = 2, figsize=(20, 8), dpi = 80)

# 绘制图像
axes[0].plot(x, y_shanghai, color="r", linestyle="--", label="上海")
axes[1].plot(x, y_beijing, color="b", linestyle="-.", label="北京")

# 显示图例
axes[0].legend()
axes[1].legend()

# 刻度修改
x_label = ["11点{}分".format(i) for i in x] # 准备x的刻度说明a
axes[0].set_xticks(x[::5])
axes[0].set_xticklabels(x_label[::5])
axes[0].set_yticks(range(0, 40, 5))

axes[1].set_xticks(x[::5])
axes[1].set_xticklabels(x_label[::5])
axes[1].set_yticks(range(0, 40, 5))

# 添加网格显示
axes[0].grid(linestyle="--", alpha=0.5)
axes[1].grid(linestyle="--", alpha=0.5)

# 添加描述信息
axes[0].set_xlabel("时间")
axes[0].set_ylabel("温度")
axes[0].set_title("上海中午11点0分到12点之间的温度变化图示")
axes[1].set_xlabel("时间")
axes[1].set_ylabel("温度")
axes[1].set_title("北京中午11点0分到12点之间的温度变化图示")

plt.show()
```

![image-20210905170009965](.\pic\image-20210905170009965.png)

#### 其他图像

```python
import matplotlib.pyplot as plt
import numpy as np 

x = np.linspace(-10, 10, 1000)
y = np.sin(x)

plt.figure(figsize=(40, 8), dpi = 100)

plt.plot(x, y)
plt.grid()

plt.show()
```

![image-20210905170744698](.\pic\image-20210905170744698.png)

```python
import matplotlib.pyplot as plt
import numpy as np

x = np.linspace(-1, 1, 1000) # 左闭右闭
y = 2 * x * x

plt.figure(figsize=(40, 8), dpi = 100)

plt.plot(x, y)
plt.grid()

plt.show()
```

![image-20210905171218283](.\pic\image-20210905171218283.png)

### 散点图

```python
import matplotlib.pyplot as plt

x = [1, 2, 3, 4, 5, 6, 7]
y = [2, 3, 4, 7, 7, 8, 8]

plt.figure(figsize=(20, 8), dpi=100)

plt.scatter(x, y)

plt.show()
```

![image-20210905172340123](.\pic\image-20210905172340123.png)

### 柱状图

```python
import matplotlib.pyplot as plt

# 准备数据
movice_name = ['雷神3：诸神黄昏','正义联盟','东方快车谋杀案','寻梦环游记','全球风暴', '降魔传','追捕','七十七天','密战','狂兽','其它']
tickets = [73853,57767,22354,15969,14839,8725,8716,8318,7916,6764,52222]

# 创建画布
plt.figure(figsize=(20, 8), dpi = 100)

# 绘制柱状图
x_ticks = range(len(movice_name))
plt.bar(x_ticks, tickets, color=['b', 'r', 'g', 'y', 'c', 'm', 'y', 'k', 'c', 'g', 'b'])  # 有几个类别， y

# 修改x的刻度
plt.xticks(x_ticks, movice_name)


# 添加标题
plt.title("电影票房收入对比")

# 添加网格显示
plt.grid(linestyle="--", alpha=0.5)

# 显示图像
plt.show()
```

![image-20210905174649434](.\pic\image-20210905174649434.png)

```python
import matplotlib.pyplot as plt
movice_name = ['雷神3：诸神黄昏', '正义联盟', '寻梦环游记']
first_day = [10587.6, 10062.5, 1275.7]
first_weekend = [36224.9, 34479, 11830]

# 创建画布
plt.figure(figsize=(20, 8), dpi = 100)

plt.bar(range(3), first_day,width = 0.2, label = "首日票房")
plt.bar([0.2, 1.2, 2.2], first_weekend, width = 0.2,  label = "首周票房")

# 修改刻度
plt.xticks([0.1, 1.1, 2.1], movice_name)

# 显示图例
plt.legend()

plt.show()
```

![image-20210905191901060](.\pic\image-20210905191901060.png)

### 直方图

```python
import matplotlib.pyplot as plt

time = [131,  98, 125, 131, 124, 139, 131, 117, 128, 108, 135, 138, 131, 102, 107, 114, 119, 128, 121, 142, 127, 130, 124, 101, 110, 116, 117, 110, 128, 128, 115,  99, 136, 126, 134,  95, 138, 117, 111,78, 132, 124, 113, 150, 110, 117,  86,  95, 144, 105, 126, 130,126, 130, 126, 116, 123, 106, 112, 138, 123,  86, 101,  99, 136,123, 117, 119, 105, 137, 123, 128, 125, 104, 109, 134, 125, 127,105, 120, 107, 129, 116, 108, 132, 103, 136, 118, 102, 120, 114,105, 115, 132, 145, 119, 121, 112, 139, 125, 138, 109, 132, 134,156, 106, 117, 127, 144, 139, 139, 119, 140,  83, 110, 102,123,107, 143, 115, 136, 118, 139, 123, 112, 118, 125, 109, 119, 133,112, 114, 122, 109, 106, 123, 116, 131, 127, 115, 118, 112, 135,115, 146, 137, 116, 103, 144,  83, 123, 111, 110, 111, 100, 154,136, 100, 118, 119, 133, 134, 106, 129, 126, 110, 111, 109, 141,120, 117, 106, 149, 122, 122, 110, 118, 127, 121, 114, 125, 126,114, 140, 103, 130, 141, 117, 106, 114, 121, 114, 133, 137,  92,121, 112, 146,  97, 137, 105,  98, 117, 112,  81,  97, 139, 113,134, 106, 144, 110, 137, 137, 111, 104, 117, 100, 111, 101, 110,105, 129, 137, 112, 120, 113, 133, 112,  83,  94, 146, 133, 101,131, 116, 111,  84, 137, 115, 122, 106, 144, 109, 123, 116, 111,111, 133, 150]

# 创建画布
plt.figure(figsize = (20, 8), dpi = 80)

# 创建直方图
distance = 2 # 柱距
group_num = (max(time) - min(time)) // distance # 柱数
plt.hist(time, bins = group_num, density = True)

# 修改x轴刻度
plt.xticks(range(min(time), max(time)+2, distance))

# 添加网格
plt.grid(linestyle = "-.", alpha = 0.5)

# 添加标题
plt.title("******")
# 显示图像
plt.show()
```

![image-20210905201137397](.\pic\image-20210905201137397.png)

### 饼图

```python
import matplotlib.pyplot as plt

# 准备数据
movice_name = ['雷神3：诸神黄昏','正义联盟','东方快车谋杀案','寻梦环游记','全球风暴', '降魔传','追捕','七十七天','密战','狂兽','其它']
place_count = [73853,57767,22354,15969,14839,8725,8716,8318,7916,6764,52222]

# 创建画布
plt.figure(figsize = (20, 8), dpi = 80)

# 绘制饼图
plt.pie(place_count, labels=movice_name, colors = ['b', 'r', 'g', 'y', 'c', 'm', 'y', 'k', 'c', 'g', 'r'], autopct = "%1.2f%%")

plt.axis("equal")

# 显示图例
plt.legend()

# 显示图像
plt.show()
```

![image-20210905202201244](.\pic\image-20210905202201244.png)





------



## Numpy

- 什么是Numpy？

    Numpy是一个开源的python科学计算库，用于快速处理任意维度的数组，Numpy支持常见的数组和矩阵操作。对于同样的数值计算任务，使用Numpy要简洁的多。

    Numpy使用ndarray对象来处理多维数组，该对象是一个快速而灵活的大数据的容器。

- 什么是ndarray？

    Numpy提供了一个N维数组类型的ndarray，它描述了相同类型的 ‘’ items ’‘ 的集合，对数组的存储效率和输入输出性能远优于python中的嵌套列表，数组越大，Numpy的优势就越明显。

- ndarray的优势

    - 内存块风格
        - ndarray中所有的元素的类型都是相同的，而python列表中的元素类型是任意的，所以ndarray在存储元素的时内存可以连续，而python原生的list就只能通过寻址的方式找到下一个元素，这虽然也导致了在通用性能方面Numpy的ndarray不及Python原生的list，但是在科学运算中，Numpy的ndarra就可以省去很多的循环语句，代码使用方面比Python的原生的list简单的多。
    - 并行化运算
        - ndarray支持并行化运算（向量化运算）
    - 底层语言
        - Numpy底层使用c语言编写，内部解除了GIL（全局解释器锁），其对数组的操作速度不受Python解释器的限制，效率远高于纯python代码。

### ndarray的属性

```python
ndarray.shape	数组维度的元组
ndarray.ndim	数组维数
ndarray.size	数组中元素的数量
ndarray.itemsize	一个数组元素的长度（字节）
ndarray.dtype	数组元素的类型
```

```python
import numpy as np

score = np.array([
    [80, 89, 86, 67, 79],
    [78, 97, 89, 67, 81],
    [90, 94, 78, 67, 84],
    [91, 91, 90, 67, 69],
    [76, 87, 75, 67, 86],
    [70, 79, 84, 67, 84],
    [94, 92, 93, 67, 64],
    [86, 85, 83, 67, 80]
])

score.shape # (8, 5)
score.ndim # 2
score.size # 40
score.dtype # dtype('int32')
score.itemsize # 4
```

### ndarray形状

```python
import numpy as np

a = np.array([[1,2, 3], [4, 5, 6]])
b = np.array([1, 2, 3, 4])
c = np.array([[[1, 2, 3], [4, 5, 6]], [[1, 2, 3], [4, 5, 6]]])

a.shape # (2, 3)
b.shape # (4, )
c.shape # (2, 2, 3)
```

### ndarray类型

![image-20210906151555036](.\pic\image-20210906151555036.png)

```python
import numpy as np

a = np.array([1, 2, 3, 4, 5])
b = np.array([1.1, 1.2, 1.3])

a.dtype  # dtype('int32')
b.dtype  # dtype('float64')

c = np.array([1, 2, 3, 4], dtype = np.float64)
c.dtype  # dtype('float64')
```

### 生成数组的方法

#### 生成0和1的数组

```python
np.zeros(shape)
np.ones(shape)
```

```python
import numpy as np

np.zeros(shape = (3, 4), dtype = "float32")
np.ones(shape = [2, 3], dtype = np.int32)
```

#### 从现有数组中生成

```python
np.array() # 深拷贝
np.copy() # 深拷贝
np.asarray() # 浅拷贝
```

#### 生成固定范围的数组

```python
np.linspace(0, 10, 1000) # 生成0~1区间段有1000个数，生成的特点是 左闭右闭，等距离的 
np.arange(a, b, c) # 左闭右开 c是步长 
```

```python
import numpy as np

np.linspace(0, 10, 5)  # array([ 0. ,  2.5,  5. ,  7.5, 10. ])
np.arange(0, 10, 5) # array([0, 5])
```

#### 生成随机数组

##### 均匀分布

```python
np.random.uniform(low=0.0, high=1.0, size=None) # 从一个均匀分布的[low， high)中随机采样，注意定义域是左闭右开
```

```python
import numpy as np
import matplotlib.pyplot as plt

data1 = np.random.uniform(low=-1, high=1, size = 1000000)

plt.figure(figsize=(20, 8), dpi = 80)

plt.hist(data1, 1000)

plt.show()

```

![image-20210906181351166](.\pic\image-20210906181351166.png)

##### 正态分布

正态分布是一种概率分布。正态分布是具有两个参数∪和⊕的连续型随机变量的分布,第一个参数∪是服从正太分布的随机变量的均值,第二个参数⊕是此随机变量的标准差 ,所以正态分布记作N(∪,⊕)

![image-20210906182431339](.\pic\image-20210906182431339.png)

 

```python
np.random.normal(loc=0.0, scale=1.0, size=None)
```

```python
import numpy as np
import matplotlib.pyplot as plt

data2 = np.random.normal(loc=1.75, scale=0.1, size = 1000000)

plt.figure(figsize=(20, 8), dpi = 80)

plt.hist(data2, 1000)

plt.show()

```

![image-20210906183246707](.\pic\image-20210906183246707.png)

### 基本操作

#### 获取数据

```python
 # 随机生成8只股票2周的交易日涨幅数据
import numpy as np
import matplotlib.pyplot as plt

store_change = np.random.normal(loc=0, scale=1, size=(8, 10))
store_change
# 获取第一个股票前3个交易日的涨跌幅数据
store_change[0, 0:3]

a1 = np.array([[[1, 2, 3], [4, 5, 6]], [[12, 3, 34], [5, 6, 7]]]) # (2, 2, 3)
a1[1, 0, 2] # 34
```

#### 形状修改

```python
ndarray.reshape(shape) # 只是修改了形状,返回新的ndarray，原始数据没有改
ndarray.resize(shape) # 只改变形状，没有返回值，对原始的ndarray进行修改
# 自动计算 shape(-1, b)
ndarray.T # 转置
```



```
# 需求：让刚才的股票行，日期列反过来，变成日期行，股票列
import numpy as np
import matplotlib.pyplot as plt

store_change = np.random.normal(loc=0, scale=1, size=(8, 10))
store_change
# 获取第一个股票前3个交易日的涨跌幅数据
store_change[0, 0:3]

store_change.T
```

#### 类型的修改

```python
ndarray.astype(type)
ndarray.toString() # ndarray序列化到本地
```

#### 数组的去重

```python
ndarray.unique() # 去重
```

### ndarray的运算

#### 逻辑运算

```python
import numpy as np
import matplotlib.pyplot as plt

store_change = np.random.normal(loc=0, scale=1, size=(8, 10))

# 如果涨跌幅大于0.5就标记为true,否则为false

store_change > 0.5
/*
array([[False, False,  True, False, False, False,  True, False,  True,
        False],
       [False, False, False,  True, False, False, False,  True, False,
        False],
       [False, False, False, False, False, False, False,  True, False,
        False],
       [ True,  True, False, False,  True, False, False, False, False,
        False],
       [ True,  True,  True, False, False, False, False, False, False,
        False],
       [ True, False,  True, False, False, False,  True, False, False,
         True],
       [False, False, False,  True,  True, False, False, False, False,
        False],
       [False,  True,  True, False, False, False, False,  True, False,
        False]])
*/


```

```python
import numpy as np
import matplotlib.pyplot as plt

store_change = np.random.normal(loc=0, scale=1, size=(8, 10))

# 如果涨跌幅大于0.5就标记为true,否则为false

# store_change > 0.5

store_change[store_change > 0.5] = 1.1
store_change
/*
array([[ 7.77778246e-02, -2.84650998e+00,  1.10000000e+00,
        -6.62919583e-01, -4.93193322e-01, -3.92657789e-01,
        -1.42678471e+00, -8.27906236e-01, -6.17788476e-01,
         1.10000000e+00],
       [-1.45580340e+00, -2.34808317e-01,  1.10000000e+00,
        -1.58087059e+00, -6.06375323e-01,  4.12311261e-01,
        -1.07785235e+00,  4.32473676e-02, -1.17852930e+00,
        -1.73899883e+00],
					··············
       [ 1.10000000e+00,  1.10000000e+00,  1.10000000e+00,
        -1.44664443e+00,  3.01976087e-01, -9.48075071e-01,
        -4.33025390e-01,  1.19762722e-01,  2.85128714e-01,
        -1.08100253e+00],
       [-3.05908988e-01, -1.63310263e+00,  1.10000000e+00,
        -5.17473855e-02,  3.97517613e-01,  1.98748821e-02,
         4.05582814e-01, -8.17822018e-01,  4.07352207e-01,
         3.83072097e-01]])
*/
```

##### 通用判断函数

```python
np.all(布尔值) # 只要有一个False就返回false，只有全是True才返回true
np.any(布尔值) # 只要有一个True就返回True，只有全部为False才返回False
```

```python
import numpy as np
import matplotlib.pyplot as plt

store_change = np.random.normal(loc=0, scale=1, size=(8, 10))

# 判断store_change[0:2, 0:5]是否全是上涨的
np.all(store_change[0:2, 0:5] > 0) # False

# 判断前五支股票这段期间是否有上涨
np.any(store_change[:5, :] > 0) # True
```

##### 三元运算符

```python
np.where(布尔值, True的位置的值, False的位置的值) 
np.logical_and(条件1， 条件2) # 逻辑运算符
np.logical_or(条件1， 条件2)
```

```python
import numpy as np
import matplotlib.pyplot as plt

store_change = np.random.normal(loc=0, scale=1, size=(8, 10))

temp = store_change[:4, :4]
np.where(temp > 0, 1, 0)
/*
array([[1, 1, 1, 1],
       [1, 1, 0, 0],
       [0, 1, 0, 1],
       [0, 1, 0, 0]])
*/
```



#### 统计运算

##### 统计指标函数

min, max, mean(平均值), median, var(方差), std(标准差)

```python
import numpy as np
import matplotlib.pyplot as plt

store_change = np.random.normal(loc=0, scale=1, size=(8, 10))


# 判断前四个股票前四天的涨跌幅 大于0的置为1 否则为0
temp = store_change[:4, :4]

# np.max(temp)
temp.max(axis = 0) # 0按列求最大值  1 按行求最
```

##### 返回最大值，最小值所在位置

```python
np.argmax(temp, axis=)
np.argmin(temp, axis=)
```

```python
import numpy as np
import matplotlib.pyplot as plt

store_change = np.random.normal(loc=0, scale=1, size=(8, 10))

temp = store_change[:4, :4]

np.argmax(temp, axis=-1) # array([2, 2, 3, 0], dtype=int64)
```

#### 数组间运算

##### 数组与数的运算

```python
ndarray + 1
运算符等
```

##### 数组与数组的运算

要求两个ndarray 满足广播机制

```
ndarray1 + ndarray2
```

##### 广播机制

**执行broadcast的前提在于，两个ndarray执行的是element-wise的运算，Broadcast机制的功能是为了方便不同形状的ndarray进行数学运算，当操作两个数组是，numpy会逐个比较它们的shape，只有在下述情况下，两个数组才能够进行数组与数组的运算。**

- **维度相等**
- **shape（其中相对应的一个地方为1）**

 ![image-20210906211323832](.\pic\image-20210906211323832.png)

##### 矩阵运算

两种方法存储矩阵：

ndarray 二维数组

matrix 数据结构  np.mat(**)

**矩阵乘法运算：**

形状：（m, n） * (n, l)  = (m, l)

**运算规则**:

- 如果是ndarray的结构：

    ​	np.matnul(array, array)

    ​	np.dot(array, array)

- 如果是matrix的结构:

    ​	mat1 * mat2



#### 合并，分割的用处

```python
numpy.hstack(tup) # 水平
numpy.vstack(tup) # 竖直
numpy.concatenate((a1, a2, a3,...), axis=0) # 0是竖直拼接
numpy.split(ary, indices_or_sections, axis=0)
```

### IO操作和数据处理

```python
texnp.genfromtxt("***", delimiter=",")
```

------



## Pandas

什么是Pandas？

- 2008年WesMckinney开发的库
- 专门用于数据挖掘的开源python库
- 以Numpy为基础，借力Numpy模块在计算方面性能高的优势
- 基于matplotlib，能够简便的画图
- 独特的数据结构

核心数据结构：

- DataFrame
- Panel
- Series

### DataFrame

- 结构：既有行索引，又有列索引的二维数组

```python
# -*- encoding: utf-8 -*-
"""
@File    : demo01_DataFrame.py
@Time    : 2021/9/7 20:28
@Author  : 岳昌宏
@Email   : 2291890518@qq.com
@Software: PyCharm
"""

import numpy as np
import pandas as pd

# 创建一个符合正态分布的10个股票的5天的涨跌幅数据
stock_change = np.random.normal(0, 1, (10, 5))

# 添加行列索引
stock = ["股票{}".format(i) for i in range(10)] # 添加行索引
date = pd.date_range(start="20180101", periods=5, freq="B")# 添加列索引
dataframe = pd.DataFrame(stock_change, stock, date)

print(dataframe)

/*
输出结果：
     2018-01-01  2018-01-02  2018-01-03  2018-01-04  2018-01-05
股票0   -0.802365   -0.633436   -0.685347    0.193362    0.685613
股票1   -1.273951   -0.936942   -0.097411    0.186454    0.109738
股票2   -0.517009    1.612196   -0.390844   -1.290394    0.418181
股票3   -0.092196   -0.254635    1.012643    2.034280    0.656286
股票4    1.067216   -0.462618    0.398016   -1.537230   -0.539264
股票5    0.227965    0.266802   -0.220648   -0.351347    1.050506
股票6   -0.108396    0.702085   -3.640980    1.126790    0.552895
股票7   -0.828635   -0.061979    0.836997    0.452572   -0.777004
股票8    2.225811    1.058938   -2.073572    0.287487   -0.178675
股票9   -0.820033   -0.245704    1.162504    0.391300   -1.110940

*/
```

- 属性：
    - shape：形状
    - index：DataFrame的行索引列表
    - columns：DataFrame的列索引列表
    - values：直接获取其中array的值
    - T：对行列的转置

```python
print(dataframe.shape) # (10, 5)
print(dataframe.values)
print(dataframe.index) # Index(['股票0', '股票1', '股票2', '股票3', '股票4', '股票5', '股票6', '股票7', '股票8', '股票9'], dtype='object')
print(dataframe.columns)
'''
DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',
               '2018-01-05'],
              dtype='datetime64[ns]', freq='B')
'''

print(dataframe.T)
```

- 方法：
    - head(num)：默认返回前五行
    - tail(num)：默认返回后五行



#### DataFrame索引值的设置

- 修改行列索引值
    - 不能单独修改索引，要想修改必须全部的修改

```python
stock_ = ["股票_{}".format(i) for i in range(10)]

dataframe.index = stock_
/*
输出结果：
      2018-01-01  2018-01-02  2018-01-03  2018-01-04  2018-01-05
股票_0   -0.922084   -0.314697    0.681554   -0.113521    0.030318
股票_1   -1.105473    0.434260    1.779841   -0.362668    1.028760
股票_2    0.464742   -1.544942    0.288548   -0.047757    1.682909
股票_3   -1.658261    1.716322   -0.235597    0.944028   -0.485395
股票_4    1.819818   -0.573014   -1.618524   -1.296449   -1.341305
股票_5    0.405877    0.542087    0.666533   -0.340536    0.230973
股票_6    0.099198   -0.487725   -0.176512   -1.545197    0.102772
股票_7   -1.209917    1.320856   -0.194675    1.811766   -1.002365
股票_8   -0.740776   -0.181764    1.310004   -2.025589   -0.649663
股票_9   -1.407518   -0.472652    1.156162    1.383231    0.382752
*/
```

- 重设索引

```python
dataframe.reset_index(drop=False)
```

- 设置新索引

```python
dataframe2 = pd.DataFrame({'month':[1, 4, 7, 10], 'year':[2021, 2022, 2023, 2024], 'sale':[55, 40, 84, 31]})
print(dataframe2)

/*
   month  year  sale
0      1  2021    55
1      4  2022    40
2      7  2023    84
3     10  2024    31
*/

dataframe2 = dataframe2.set_index("month", drop=False)
print(dataframe2)

/*
       month  year  sale
month                   
1          1  2021    55
4          4  2022    40
7          7  2023    84
10        10  2024    31
*/

dataframe2 = dataframe2.set_index("month", drop=True)
print(dataframe2)

/*
       year  sale
month            
1      2021    55
4      2022    40
7      2023    84
10     2024    31
*/

dataframe2 = dataframe2.set_index(["year", "sale"], drop=True)
print(dataframe2)

/*
           month
year sale       
2021 55        1
2022 40        4
2023 84        7
2024 31       10
*/
```

### Multilndex与Panel

#### MultiIndex

- index的属性
    - names：levels的名称
    - levels：每个level的元组值

```python
dataframe2 = dataframe2.set_index(["year", "sale"], drop=True)
/*
           month
year sale       
2021 55        1
2022 40        4
2023 84        7
2024 31       10
*/

print(dataframe2.index)
/*
MultiIndex([(2021, 55),
            (2022, 40),
            (2023, 84),
            (2024, 31)],
           names=['year', 'sale'])
*/
print(dataframe2.index.names) # ['year', 'sale']
print(dataframe2.index.levels) # [[2021, 2022, 2023, 2024], [31, 40, 55, 84]]
```

#### Panel

```python
p = pd.Panel(data=np.arange(24).reshape(4,3,2),
                 items=list('ABCD'),
                 major_axis=pd.date_range('20130101', periods=3),
                 minor_axis=['first', 'second'])
 
# 结果
<class 'pandas.core.panel.Panel'>
Dimensions: 4 (items) x 3 (major_axis) x 2 (minor_axis)
Items axis: A to D
Major_axis axis: 2018-01-01 00:00:00 to 2018-01-03 00:00:00
Minor_axis axis: first to second

#  python3是读取不了上面的数据的
```

### Series

带索引的一维数组,series结构只有行索引

```python
print(dataframe.iloc[1, :])

/*
2018-01-01    0.858577
2018-01-02   -0.921147
2018-01-03    0.028350
2018-01-04   -0.362713
2018-01-05    0.354388
Freq: B, Name: 股票1, dtype: float64
*/
```

- 属性
    - index
    - values

```python
ser = pd.Series(np.array(range(3, 9, 2)))
print(ser)

/*
0    3
1    5
2    7
dtype: int32
*/

ser2 = pd.Series(np.array(range(3, 9, 2)), index=["a", "b", "c"])
print(ser2)

/*
a    3
b    5
c    7
dtype: int32
*/

ser3 = pd.Series({"A":11, "B":22, "C":33})
print(ser3)

/*
A    11
B    22
C    33
dtype: int64
*/
```

可以理解说DataFrame是Series的容器，Panel是DataFrame的容器

### 基本数据操作

```python
import numpy as np
import pandas as pd

data = pd.read_csv("../file/stock_day.csv")
# 删除一些列，让数据更简单些
data = data.drop(["ma5", "ma10", "ma20", "v_ma5", "v_ma10", "v_ma20"], axis=1) # 按列
```

- 索引操作

```python
# 直接索引(先列后行)
print(data["open"]["2018-02-26"]) # 22.8
# 按名字索引(先行后列)
print(data.loc["2018-02-26"]["open"]) # 22.8
print(data.loc["2018-02-26", "open"]) # 22.8
# 按数字索引
print(data.iloc[1, 0]) # 22.8
# 组合索引
# print(data.ix[:4, 'open', 'close'])  # 已经删除
```

- 赋值操作

```python
data.open = 100 # 对象.属性
data.iloc[1, 0] = 22

print(data)
```

- 排序操作
    - 对内容排序
        - dataframe
        - series
    - 对索引排序
        - dataframe
        - series

```python
data.sort_values(by="high", ascending=True) # 默认升序，按照一个字段进行排序

data.sort_values(by=["high", "p_change"], ascending=True) # 按照两个字段进行排序

data.sort_index()
```

### 算术运算与逻辑运算

- 算术运算
    - data["open"].add(3)  / data["open"] + 3
    - data["open"].sub(3) / data["open"] - 3
    - .....
    - 也可以一一对应的算术
- 逻辑运算
    - 逻辑运算符
        - <,> 返回布尔值
        - data["p_change"] > 2
        - data[data["p_change"] > 2] 
    - 逻辑运算函数
        - query()
            - data.query("p_change" > 2 & "low" > 15)
        - isin() : 判断是否包含返回布尔值
            - data["turnover"].isin([4.19, 2.39])
- 统计运算
    - min max mean median var std
    - describe()
    - idxmax() : 获取最大知道额位置
    - idxmin()
    - 累加统计函数
        -  cumsun
- 自定义运算
    - apply(func,axis = 0) : func自定义函数。默认是按照列进行运算
        - data.apply(lambda x : x.max() - x.min())



### Pandda画图

.plot()

```python

data.plot("p_change", "turnover", "scatter")

plt.show()
```

![image-20210907224902638](.\pic\image-20210907224902638.png)

### 文件的读取与存储

![image-20210908111158160](.\pic\image-20210908111158160.png)

#### CSV

```python
import numpy as np
import pandas as pd

data = pd.read_csv("../file/stock_day.csv", usecols=['open', 'high', 'colse'])
# 删除一些列，让数据更简单些
# data = data.drop(["ma5", "ma10", "ma20", "v_ma5", "v_ma10", "v_ma20"], axis=1) # 按列
```

![image-20210908111947186](.\pic\image-20210908111947186.png)

```python
# 如果表中没有索引，会将第一行作为字段

data = pd.read_csv("../file/stock_day2.csv", names=[字段])
```

- 存储csv

```python
# 保存‘open’列的数据

data[:10].to_csv(path, column=['要保存的列'], index=False, mode="a", head=False) # 不要行索引,追加模式,不要追加头所有
```

#### HDF5

hdf5存储3维数据的文件

key1 dataframe1

key2 dataframe2

....

```python
pd.read_hdf('path', key='**') # 当有一个key时，可以不指定key

df.to_hdf('path1',key='**1')
df.to_hdf('path1',key='**2')
```

HDF5在存储的是支持压缩，使用的方式是blosc，这个是速度最快的也是pandas默认支持的

使用压缩可以提高磁盘利用率，节省空间

HDF5还是跨平台的，可以轻松迁移到hadoop上面

#### JSON

Json是一种数据交换格式，前后端交互经常用到，也会在存储的时候选择这种格式，所以我们需要知道Pandas如何进行读取和存储Json格式。

```python
pd.read_json('path', orient='records', lines=True) # 读取格式，是否按行读取

data.to_json('path',orient='records', lines=True)
```

## Pandas高级处理

### 缺失值处理

- 如何进行缺失值nan处理：
    - 删除含有缺失值的样本
    -  替换/插补
- 如何处理nan：
    - 判断数据中是否存在nan：``pd.isnull(df) / pd.notnull(df)``
    - 删除含有缺失值的样本``df.dropna(axis='rows', inplace=True/False)`` 默认是按行删除。如果是True就就地删除，如果是False不会修改df，而是返回一个删除后的df，默认是False
    - 替换插补``df.fillna(value, inplace=True/False)``
- 如果缺失值不是nan而是？号等其他标记：
    - 替换``df.replace(to_replace=, value=np.nan)``to_replace:替换前的值，value替换后的值
    - 把其他符合替换成nan

```python
'''
是否存在nan类型的缺失值
'''
import pandas as pd
import numpy as np

# 读取数据
movie = pd.read_csv("../file/IMDB-Movie-Data.csv")

# 判断是否存在缺失值
nan = pd.isnull(movie).any()

# 缺失值处理
# 删除含有缺失值的样本
# movie.dropna(inplace=True)
# 替换
movie["Revenue (Millions)"].fillna(movie["Revenue (Millions)"].mean(), inplace=True)
movie["Metascore"].fillna(movie["Metascore"].mean(), inplace=True)

nan2 = pd.isnull(movie).any()

print(nan)
print(nan2)
print(movie)
'''
Rank                  False
Title                 False
Genre                 False
Description           False
Director              False
Actors                False
Year                  False
Runtime (Minutes)     False
Rating                False
Votes                 False
Revenue (Millions)     True
Metascore              True
dtype: bool
Rank                  False
Title                 False
Genre                 False
Description           False
Director              False
Actors                False
Year                  False
Runtime (Minutes)     False
Rating                False
Votes                 False
Revenue (Millions)    False
Metascore             False
dtype: bool
     Rank                    Title  ... Revenue (Millions) Metascore
0       1  Guardians of the Galaxy  ...         333.130000      76.0
1       2               Prometheus  ...         126.460000      65.0
2       3                    Split  ...         138.120000      62.0
3       4                     Sing  ...         270.320000      59.0
4       5            Suicide Squad  ...         325.020000      40.0
..    ...                      ...  ...                ...       ...
995   996     Secret in Their Eyes  ...          82.956376      45.0
996   997          Hostel: Part II  ...          17.540000      46.0
997   998   Step Up 2: The Streets  ...          58.010000      50.0
998   999             Search Party  ...          82.956376      22.0
999  1000               Nine Lives  ...          19.640000      11.0
'''
```

```python
'''
是否存在不是nan类型的缺失值
'''
import pandas as pd
import numpy as np

# 读取数据
data = pd.read_csv("../file/IMDB-Movie-Data.csv")

# 替换 ？ -> np.nan
data_new = data.replace(to_replace="?", value=np.nan)

# 按照nan的方式进行处理
# 删除缺失值
data_new.dropna(replace=True)

print(data_new)
```



### 数据离散化

- 什么是数据离散化？

one-hot编码 / 哑变量

![image-20210909192823604](.\pic\image-20210909192823604.png)

- 为什么要数据的离散化？
    - 连续属性离散化的目的是为了简化数据结构，数据离散化技术可以用来减少给定连续属性值的个数，离散化方法经常作为数据挖掘的工具
- 如何实现数据的离散化？
    - 分组
        - 自动分组 ``sr = pd.qcut(data, bins)``
        - 自定义分组``sr = pd.cut(data, [])``
    - 将分组好的结果转换成哑变量
        - ``pd.get_dummies(sr, prefix='前缀', )``

```python
import numpy as np
import pandas as pd

# 准备数据
data = pd.Series([165, 174, 160, 180, 159, 163, 192, 184], index=['No1:165','No2:174','No3:160','No4:180','No5:159','No6:163','No7:192','No8:184'])
# 分组
# 自动分组
# sr = pd.qcut(data, 3)
# 自定义分组
sr = pd.cut(data, [150, 165, 180, 195])
print(sr.value_counts())
print("------")
# 转换成哑变量
data2 = pd.get_dummies(sr, prefix="身高")

print(data2)

'''
(150, 165]    4
(180, 195]    2
(165, 180]    2
dtype: int64
------
         身高_(150, 165]  身高_(165, 180]  身高_(180, 195]
No1:165              1              0              0
No2:174              0              1              0
No3:160              1              0              0
No4:180              0              1              0
No5:159              1              0              0
No6:163              1              0              0
No7:192              0              0              1
No8:184              0              0              1

Process finished with exit code 0
'''
```



### 合并

- 按方向拼接``pd.concat([data1, data2], axis=0)``默认竖直拼接（行索引一样水平拼接， 列索引一样竖直拼接）
- 按索引拼接``pd.merge(left, right, how="inner", on=[索引])``
    - ![image-20210909203910918](.\pic\image-20210909203910918.png)
    - ![image-20210909203857025](.\pic\image-20210909203857025.png)
    - ![image-20210909204134598](.\pic\image-20210909204134598.png)

### 交叉表和透视表

- 交叉表：交叉表用于计算一列数据对于另一列数据的分组个数（寻找两个列之间的关系）
    - ``pd.crosstab(value1, value2)``

 

```python

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# 星期数据以及涨跌幅是好是坏数据
stock = pd.read_csv("../file/stock_day.csv")
# 准备星期数据列
date = pd.to_datetime(stock.index)
stock["week"] = date.weekday
# 准备涨跌幅数据列
stock["pona"] = np.where(stock["p_change"] > 0, 1, 0)

# 调用交叉表
cross = pd.crosstab(stock["week"], stock["pona"])

cross_sum = cross.div(cross.sum(axis=1), axis = 0)

cross_sum.plot(kind="bar", stacked=True)


plt.show()
print(cross_sum)

'''
pona         0         1
week                    
0     0.504000  0.496000
1     0.419847  0.580153
2     0.462121  0.537879
3     0.492188  0.507812
4     0.464567  0.535433
'''
```

![image-20210909211150545](.\pic\image-20210909211150545.png)

- 透视表``data.prvot_table([], index=[])``

### 分组与聚合

- 分组

```python
import pandas as pd
import numpy as np

col = pd.DataFrame({'color': ['white','red','green','red','green'], 'object': ['pen','pencil','pencil','ashtray','pen'],'price1':[5.56,4.20,1.30,0.56,2.75],'price2':[4.75,4.12,1.60,0.75,3.15]})

# 进行分组，对颜色分组，price进行聚合
# 用dataframe进行分组
# col = col.groupby(by="color")["price1"].max()
col = col["price1"].groupby(col["color"]).max()

print(col)
'''
color
green    2.75
red      4.20
white    5.56
Name: price1, dtype: float64
'''
```





------



## 决策树

决策树是一种**非参数**（不限制数据的结构和类型）的有**监督的学习**方法，它能够从一系列有**特征**和**标签**的数据中总结出决策规则，并用树状图的结构来呈现这些规则，以解决分类和回归问题。

在决策过程中，我们一直对记录的特征进行提问，最初的问题所在的地方叫做**根节点**，在得到结论前的每一个问题都是**中间节点**，而得到的每一个结论都叫做**叶子节点**。



根节点：没有进边，有出边。包括最初，针对特征的提问。

中间节点：既有进边也有出边，进边只有一条，出边可以有很多条，都是针对特征提问的。

叶子节点：有进边，没有出边，**每个叶子节点都是一个类别的标签**



- 决策树算法的核心是要解决两个问题？
    - 如何从数据表中找出最佳节点和最佳分支
    - 如何让决策树停止生长，防止过拟合？



- sklearn.tree

![image-20210911160407198](D:\Typora\Data\数据挖掘\pic\image-20210911160407198.png)



- sklearn建模的流程
    1. 实例化，建立模型评估对象		——实例化时需要使用的参数
    2. 通过模型的接口训练模型     ——数据属性，数据接口
    3. 通过模型接口提取需要的信息    ——数据属性，数据接口



### DecisionTreeClassifier与红酒数据集

- **criterion**
    - 不纯度基于节点来计算的，树中的每个节点都会有一个不纯度，并且子节点的不纯度一定是定于父节点的，也就是说，在同一颗决策树上，叶子节点的不纯度一定是最低的。
    - entropy ： 使用信息熵
    - gini ：使用基尼系数
- **random_state**:用来设置分枝中随机模式的参数，默认是None。在高维度时，随机性会表现的更明显，低维度的数据，随机性几乎不明显。输入任意的整数，会长出同一颗树，让模型稳定下来。
- **splitter**:也是用来控制决策树的随机选项的，有两种输入值，输入**“best”**，决策树在分枝时虽然随机，但是还是会优先选择更重要的特征进行分枝（更重要的分枝可以通过属性feature_importance_查看），输入**“random”**,决策树在分枝时会更加随机，树会更深，对训练集的拟合将会降低，这也是防止过拟合的一种方式。

为了让决策树有更好的范化性，我们要对决策树进行剪枝，**剪枝策略**对决策树的影响巨大，正确的剪枝策略是优化决策树算法的核心

- **max_depth:** 限制树的深度，超过设定深度的树枝全部剪掉，这是用得最广泛的剪枝参数，这是用得最广泛的剪枝参数，在高维度低样本量时非常有效。决策树多生长一层，对样本量的需求会增加一倍，所以限制树深度能够有效地限制过拟合。在集成算法中也非常实用。实际使用时，建议从=3开始尝试，看看拟合的效果再决定是否增加设定深度。

- **min_samples_leaf&min_samples_splits**:

    - min_samples_leaf一个节点在分枝后的每个子节点都必须包含至少min_samples_leaf个训练样本，否则分枝就不会发生，或者，分枝会朝着满足每个子节点都包含min_samples_leaf个样本的方向去发生

    - min_samples_split限定，一个节点必须要包含至少min_samples_split个训练样本，这个节点才允许被分枝，否则

        分枝就不会发生。

- **max_features&min_impurity_decrease:**

    - max_features:限制分枝时考虑的特征个数，超过限制个数的特征都会被舍弃。和max_depth异曲同工，

        max_features是用来限制高维度数据的过拟合的剪枝参数，但其方法比较**暴力**，是直接限制可以使用的特征数量

        而强行使决策树停下的参数，在不知道决策树中的各个特征的重要性的情况下，强行设定这个参数可能会导致模型

        学习不足。如果希望通过降维的方式防止过拟合，建议使用PCA，ICA或者特征选择模块中的降维算法。

    - min_impurity_decrease:限制信息增益的大小，信息增益小于设定数值的分枝不会发生。这是在0.19版本中更新的

        功能，在0.19版本之前时使用min_impurity_split

- **class_weight&min_weight_fraction_leaf:**完成样本标签平衡的参数。样本不平衡是指在一组数据集中，标签的一类天生占有很大的比例。比如说，在银行要判断“一个办了信用卡的人是否会违约”，就是是vs否（1%：99%）的比例。这种分类状况下，即便模型什么也不做，全把结果预测成“否”，正确率也能有99%。因此我们要使用class_weight参数对样本标签进行一定的均衡，给

    少量的标签更多的权重，让模型更偏向少数类，向捕获少数类的方向建模。该参数默认None，此模式表示自动给

    与数据集中的所有标签相同的权重。

    有了权重之后，样本量就不再是单纯地记录数目，而是受输入的权重影响了，因此这时候剪枝，就需要搭配min_

    weight_fraction_leaf这个基于权重的剪枝参数来使用。另请注意，基于权重的剪枝参数（例如min_weight_

    fraction_leaf）将比不知道样本权重的标准（比如min_samples_leaf）更少偏向主导类。如果样本是加权的，则使

    用基于权重的预修剪标准来更容易优化树结构，这确保叶节点至少包含样本权重的总和的一小部分。

- **重要属性和接口：**
    - **clf.apply(Xtest**)： 返回每个测试样本所在的叶子节点的索引
    - **clf.predict(Xtest)**：返回每个测试样本的分类/回归结果
    - 所有接口中要求输入X_train和X_test的部分，输入的特征矩阵必须至少是一个二维矩阵。sklearn不接受任何一维矩阵作为特征矩阵被输入

```python
# -*- encoding: utf-8 -*-
"""
@File    : DecisionTreeClassifier.py
@Time    : 2021/9/12 11:18
@Author  : 岳昌宏
@Email   : 2291890518@qq.com
@Software: PyCharm
"""

import graphviz
from sklearn import tree
from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split
import pandas as pd

# 红酒数据集
wine = load_wine()

print("数据集的结构：" , wine.data.shape)
print("数据集的特征：" , wine.target)
print("-" * 100)
data = pd.concat([pd.DataFrame(wine.data), pd.DataFrame(wine.target)], axis=1)
print(data)
print("-" * 100)
# 标签的名字
print(wine.target_names)
# 特征的名字
print(wine.feature_names)

print("*" * 100)

# 划分测试集和训练集
Xtrain, Xtest, Ytrain, Ytest = train_test_split(wine.data, wine.target, test_size=0.3)

clf = tree.DecisionTreeClassifier(criterion="entropy",
                                  random_state = 30,
                                  splitter = "random",
                                  max_depth=3,
                                # min_samples_leaf=10,
                                  min_samples_split=10)
clf = clf.fit(Xtrain, Ytrain)
score = clf.score(Xtest, Ytest) # 返回预测的准确度
print(score)

# 可视化
feature_name = ['酒精','苹果酸','灰','灰的碱性','镁','总酚','类黄酮','非黄烷类酚类','花青素','颜色强度','色调','od280/od315稀释葡萄酒','脯氨酸']

dot_data = tree.export_graphviz(
    clf,
    feature_names = feature_name,
    class_names = ["琴酒","雪莉","贝尔莫得"],
    filled = True, # 是否填充颜色，颜色越深不纯度越低
    rounded = True # 框的形状
)

graph = graphviz.Source(dot_data)

'''
数据集的结构： (178, 13)
数据集的特征： [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]
----------------------------------------------------------------------------------------------------
        0     1     2     3      4     5   ...    8      9     10    11      12  0 
0    14.23  1.71  2.43  15.6  127.0  2.80  ...  2.29   5.64  1.04  3.92  1065.0   0
1    13.20  1.78  2.14  11.2  100.0  2.65  ...  1.28   4.38  1.05  3.40  1050.0   0
2    13.16  2.36  2.67  18.6  101.0  2.80  ...  2.81   5.68  1.03  3.17  1185.0   0
3    14.37  1.95  2.50  16.8  113.0  3.85  ...  2.18   7.80  0.86  3.45  1480.0   0
4    13.24  2.59  2.87  21.0  118.0  2.80  ...  1.82   4.32  1.04  2.93   735.0   0
..     ...   ...   ...   ...    ...   ...  ...   ...    ...   ...   ...     ...  ..
173  13.71  5.65  2.45  20.5   95.0  1.68  ...  1.06   7.70  0.64  1.74   740.0   2
174  13.40  3.91  2.48  23.0  102.0  1.80  ...  1.41   7.30  0.70  1.56   750.0   2
175  13.27  4.28  2.26  20.0  120.0  1.59  ...  1.35  10.20  0.59  1.56   835.0   2
176  13.17  2.59  2.37  20.0  120.0  1.65  ...  1.46   9.30  0.60  1.62   840.0   2
177  14.13  4.10  2.74  24.5   96.0  2.05  ...  1.35   9.20  0.61  1.60   560.0   2

[178 rows x 14 columns]
----------------------------------------------------------------------------------------------------
['class_0' 'class_1' 'class_2']
['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']
****************************************************************************************************
0.9444444444444444

Process finished with exit code 0
'''
```

![image-20210912124433539](D:\Typora\Data\数据挖掘\pic\image-20210912124433539.png)

### DecisionTreeRegressor

几乎所有的参数，属性以及接口都和分类树一模一样，需要注意的是，在回归树中， 没有标签是否均衡的问题，因此没有class_weight这样的参数。

-  **criterion**：

    - 输入"**mse**"使用均方误差mean squared error(MSE)，父节点和叶子节点之间的均方误差的差额将被用来作为

        特征选择的标准，这种方法通过使用叶子节点的均值来最小化L2损失

    - 输入“**friedman_mse**”使用费尔德曼均方误差，这种指标使用弗里德曼针对潜在分枝中的问题改进后的均方误差

    - 输入"**mae**"使用绝对平均误差MAE（mean absolute error），这种指标使用叶节点的中值来最小化L1损失

        属性中最重要的依然是feature_importances_，接口依然是apply, fifit, predict, score最核心

- **交叉验证**：交叉验证是用来观察模型的稳定的一种方法，我们将数据划分为n份，依次使用其中的一份作为测试集，其他的n-1份作为训练集，多次计算模型的精确度来评估模型的平均准确程度，训练集和测试集的划分会干扰模型的结果，因此用交叉验证n次的结果求出的平均值，是对模型效果的一个更好的度量

![image-20210912153418302](D:\Typora\Data\数据挖掘\pic\image-20210912153418302.png)

```python
from sklearn.datasets import load_boston
from sklearn.model_selection import cross_val_score
from sklearn.tree import DecisionTreeRegressor

boston = load_boston() # target是连续的
regressor = DecisionTreeRegressor(random_state=0) # 实例化
cross_val_score(regressor, # 实例化好的模型
                boston.data,
                boston.target,
                cv=5,
                scoring = "neg_mean_squared_error"  # 均方误差， 如果注释掉默认返回R平方
               )
'''
array([-12.15176471, -52.12217822, -27.85663366, -52.6449505 ,
       -63.19168317])
'''
```



### 用回归树拟合正弦曲线

```python
import numpy as np
from sklearn.tree import DecisionTreeRegressor
import matplotlib.pyplot as plt


#np.random.rand(数组结构)，生成随机数组的函数
rng = np.random.RandomState(1) # 随机数种子 （0， 1）
X = np.sort(5 * rng.rand(80,1), axis=0)  # 生成80行1列的，并且排序
y = np.sin(X).ravel()  # np.sin(X) 生成是（80， 1）二维的，使用ravel给np.sin(X)降维

plt.figure()
plt.scatter(X, y, s=20, edgecolor="black", c="darkorange", label="data")
```

![image-20210912171609765](D:\Typora\Data\数据挖掘\pic\image-20210912171609765.png)

```python
# 在y上加上噪声
y[::5] += 3 * (0.5 - rng.rand(16))

plt.figure()
plt.scatter(X, y, s=20, edgecolor="black", c="darkorange", label="data")
```

![image-20210912171642747](D:\Typora\Data\数据挖掘\pic\image-20210912171642747.png)

```python
regr_1 = DecisionTreeRegressor(max_depth=2)
regr_2 = DecisionTreeRegressor(max_depth=5)
clf1 = regr_1.fit(X, y)
clf2 = regr_2.fit(X, y)

X_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]
# np.arange(a, b, c) # 左闭右开 c是步长  [:,np.newaxis] 增维(多行一列) [np.newaxis, :] 也是增维（一行多列）
y_1 = regr_1.predict(X_test)
y_2 = regr_2.predict(X_test)

# 画图
plt.figure()
plt.scatter(X, y, s=20, edgecolor="black",c="darkorange", label="data")
plt.plot(X_test, y_1, color="cornflowerblue",label="max_depth=2", linewidth=2)
plt.plot(X_test, y_2, color="yellowgreen", label="max_depth=5", linewidth=2)

plt.xlabel("data")
plt.ylabel("target")

plt.title("Decision Tree Regression")
plt.legend()
plt.show()
```

![image-20210912171801744](D:\Typora\Data\数据挖掘\pic\image-20210912171801744.png)

### 泰坦尼克号生存者预测

```python
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
import matplotlib.pyplot as plt
from sklearn.model_selection import GridSearchCV
```

导入数据

```python
data = pd.read_csv(r"./data/data.csv")
data.info() # 查看数据的详细内容，发现有缺失值
```

![image-20210912205237516](D:\Typora\Data\数据挖掘\pic\image-20210912205237516.png)

```python
data.head() # 默认显示前5行
```

![image-20210912205413783](D:\Typora\Data\数据挖掘\pic\image-20210912205413783.png)

```python
# 筛选特征
data.drop(['Cabin', 'Name', 'Ticket'], inplace=True,axis=1) 
# 第二个参数为true，表示：请用删除之后的表来覆盖原表, axis=1表示对列进行操作,如果多次运行会报错
```

```python
# 处理缺失值

data["Age"] = data["Age"].fillna(data["Age"].mean()) # 使用均值对缺失值进行填补
data = data.dropna(axis=0) # 删除有确实的行
data.info()
```

![image-20210912205629107](D:\Typora\Data\数据挖掘\pic\image-20210912205629107.png)

```python
# 把汉字换为数字
labels = data["Embarked"].unique().tolist() # [S, C, Q]
data["Embarked"] = data["Embarked"].apply(lambda x:labels.index(x)) # lambda x是这一列每一个数据
# 对性别这一列进行操作
data["Sex"] = (data["Sex"] == "male").astype("int")
# (data["Sex"] == "male")返回True or False 把True or False 这种类型换一种方式展示.astype("int")
```

```python
data.head()
```

![image-20210912205844653](D:\Typora\Data\数据挖掘\pic\image-20210912205844653.png)

```python
# 数据预处理完成，没有字符型，没有缺失值
data.info()
```

![image-20210912205952485](D:\Typora\Data\数据挖掘\pic\image-20210912205952485.png)

```python
# 分离特征和标签
x = data.iloc[:, data.columns != "Survived"] # 取出特征
y = data.iloc[:,data.columns == "Survived"] # 取出标签

from sklearn.model_selection import train_test_split
Xtrain, Xtest, Ytrain, Ytest = train_test_split(x, y, test_size=0.3)
```

此时Xtrain, Xtest, Ytrain, Ytest它们的索引是乱序的，所以需要纠正索引

```python
# 纠正索引
for i in [Xtrain, Xtest, Ytrain, Ytest]:
    i.index = range(i.shape[0])
    
'''
Xtrain是一个Dataframe类型的属性，其中index表示行索引列表
Xtrain.shape返回的是一个元组，表示该Xtrain有多少行和多少列，元组的第一个元素表示有多个行，第二个元素表示有多少列
'''
```

```python
Xtrain
```

![image-20210912210419595](D:\Typora\Data\数据挖掘\pic\image-20210912210419595.png)

```python
clf = DecisionTreeClassifier(random_state=25) # 设计模型
clf = clf.fit(Xtrain, Ytrain)
score = clf.score(Xtest, Ytest)

score
```

```
0.7490636704119851
```

```python
from sklearn.model_selection import cross_val_score

clf = DecisionTreeClassifier(random_state=25)

score = cross_val_score(clf, x, y, cv=10).mean() # 使用交叉验证
score
```

```
0.7469611848825333
```

```python
tr = []
te = []

for i in range(10):
    clf = DecisionTreeClassifier(random_state=25,
                                max_depth = i +1, # 改变树的深度，观察对数据评分的影响
                                 criterion = "entropy"
                                )
    clf = clf.fit(Xtrain, Ytrain)
    score_tr = clf.score(Xtrain, Ytrain) 
    score_te = cross_val_score(clf, x, y, cv = 10).mean() # 交叉验证
    tr.append(score_tr)
    te.append(score_te)

print(max(te))

# 如果训练集的曲线高于测试集的曲线，说明是过拟合的，我们可以剪枝
# 如果训练集的曲线低于测试集的曲线，说明是欠拟合的，
plt.figure()
plt.plot(range(1, 11), tr, color="red", label = "train")
plt.plot(range(1, 11), te, color="blue", label = "test")

plt.xticks(range(1, 11))
plt.legend()
plt.show()
```

![image-20210912210745630](D:\Typora\Data\数据挖掘\pic\image-20210912210745630.png)

```python
# 网格搜索：能够帮助我们调整多个参数的技术，枚举的计数
# 缺点：计算量非常的大。非常的耗费时间
```

```python
import numpy as np

# 本质是一串参数和这些参数对应的，我们希望网格希望来搜索的参数的取值范围
parameters = {"criterion":("gini", "entropy"),
              "splitter":("best", "random"),
              "max_depth":[*range(1, 10)],
              "min_samples_leaf":[*range(1, 50, 5)],
              "min_impurity_decrease":[*np.linspace(0, 0.5, 20)]
             }

clf = DecisionTreeClassifier(random_state=25)
GS = GridSearchCV(clf, parameters, cv=10) # 同时满足了fit，score，cross_val_score
GS = GS.fit(Xtrain, Ytrain)
```

```python
GS.best_params_ # 从我们输入的参数和参数的取值列表中，返回最佳组合
```

```python
{'criterion': 'entropy',
 'max_depth': 6,
 'min_impurity_decrease': 0.0,
 'min_samples_leaf': 6,
 'splitter': 'best'}
```

```python
GS.best_score_ # 网格搜索后的模型的评判标准
```

```python
0.823195084485407
```

